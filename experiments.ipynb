{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Create a simple neural network",
   "id": "53c290f969bf96f2"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "from torch_scatter.testing import reductions\n",
    "\n",
    "from nn import Linear, Module\n",
    "from optim import Adam\n",
    "from tensor import Tensor"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class MLP(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_1 = Linear(3, 3)\n",
    "        self.linear_2 = Linear(3, 6)\n",
    "        self.linear_3 = Linear(6, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = FF.tanh(self.linear_1(x))\n",
    "        x = FF.tanh(self.linear_2(x))\n",
    "        x = FF.tanh(self.linear_3(x))\n",
    "        return x\n",
    "\n"
   ],
   "id": "211df7df4f09cc87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = MLP()\n",
    "optim = Adam(model.parameters()) "
   ],
   "id": "b0e1e965fb0e7260",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "X = [\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0   , 1.0],\n",
    "    [1.0, 1.0, -1.0]\n",
    "]\n",
    "\n",
    "Y = [[1.0], [-1.0], [-1.0], [1.0]]\n",
    "\n",
    "X = Tensor(X) \n",
    "Y = Tensor(Y) "
   ],
   "id": "3e821c78c11fbe4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def mse_loss(predictions, targets):\n",
    "    return ((predictions - targets) ** 2).sum() / predictions.shape[0]"
   ],
   "id": "d37471bd158310e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    predictions = model(X)\n",
    "    loss = mse_loss(predictions, Y)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step() \n",
    "    print(f\"Epoch {epoch}, Loss: {loss.data}\")"
   ],
   "id": "98b31832a826ecbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Example 2: Comparison between derivative calculation in PyTorch and MinTorch",
   "id": "1214fff0c3705f93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import nn.functional as FF\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def arrays_are_close(arr_1, arr_2):\n",
    "    print(np.allclose(arr_1, arr_2, atol=1e-5))\n",
    "\n",
    "val_a = [\n",
    "    [1, 2, 3, 4],\n",
    "    [4, 5, 6, 10],\n",
    "    [9, -1, 1, 1]\n",
    "]\n",
    "\n",
    "val_b = [\n",
    "    [1, -2, 3, 4],\n",
    "    [4, 4, -6, 10],\n",
    "    [1, -1, 0, 1]\n",
    "]\n",
    "val_q = [\n",
    "    [2, 2, 2],\n",
    "    [2, 2, 2],\n",
    "    [2, 2, 2],\n",
    "    [2, 2, 2],\n",
    "    [2, 2, 2]\n",
    "]\n",
    "\n",
    "a_torch = torch.tensor(val_a, requires_grad=True, dtype=torch.float32)\n",
    "b_torch = torch.tensor(val_b, requires_grad=True, dtype=torch.float32)\n",
    "q_torch = torch.tensor(val_q, requires_grad=True, dtype=torch.float32)\n",
    "c_torch = F.linear(a_torch, b_torch)\n",
    "d_torch = F.linear(c_torch, q_torch)\n",
    "e_torch = d_torch.sum()\n",
    "e_torch.backward()\n",
    "\n",
    "\n",
    "a_mtorch = Tensor(val_a)\n",
    "b_mtorch = Tensor(val_b)\n",
    "c_mtorch = FF.linear(a_mtorch, b_mtorch)\n",
    "q_mtorch = Tensor(val_q)\n",
    "d_mtorch = FF.linear(c_mtorch, q_mtorch)\n",
    "e_mtorch = d_mtorch.sum()\n",
    "e_mtorch.backward()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "arrays_are_close(a_torch.grad.detach().numpy(), a_mtorch.grad) # compare de/da\n",
    "arrays_are_close(b_torch.grad.detach().numpy(), b_mtorch.grad) # compare de/da\n",
    "arrays_are_close(c_torch.grad.detach().numpy(), c_mtorch.grad) # compare de/da\n",
    "arrays_are_close(d_torch.grad.detach().numpy(), d_mtorch.grad) # compare de/da\n",
    "arrays_are_close(e_torch.grad.detach().numpy(), e_mtorch.grad) # compare de/da\n",
    "arrays_are_close(q_torch.grad.detach().numpy(), q_mtorch.grad) # compare de/da\n",
    "\n"
   ],
   "id": "dcbd8dbdff7fa64d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Example 3: High Dimensional Case",
   "id": "4e18577918c5dc0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "A = torch.tensor([\n",
    "    [\n",
    "        [1, 2, 3, 4]\n",
    "    ],\n",
    "    [\n",
    "        [1, 9, -1, 4]\n",
    "    ],\n",
    "    [\n",
    "        [1, 2, 3, -1]\n",
    "    ]\n",
    "], requires_grad=True, dtype=torch.float32)\n",
    "\n",
    "B = torch.tensor([\n",
    "    \n",
    "        [1, 9, 3, 4]\n",
    "    ,\n",
    "    \n",
    "        [0, 1, -1, -11]\n",
    "    ,\n",
    "    \n",
    "        [1, 21, 11, -1]\n",
    "    \n",
    "], requires_grad=True, dtype=torch.float32)\n",
    "\n",
    "C = F.linear(A, B)\n",
    "\n",
    "D = C.sum()\n",
    "D.backward()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "AA = Tensor([\n",
    "    [\n",
    "        [1, 2, 3, 4]\n",
    "    ],\n",
    "    [\n",
    "        [1, 9, -1, 4]\n",
    "    ],\n",
    "    [\n",
    "        [1, 2, 3, -1]\n",
    "    ]\n",
    "])\n",
    "\n",
    "BB = Tensor([\n",
    "    \n",
    "        [1, 9, 3, 4]\n",
    "    ,\n",
    "    \n",
    "        [0, 1, -1, -11]\n",
    "    ,\n",
    "    \n",
    "        [1, 21, 11, -1]\n",
    "    \n",
    "])\n",
    "\n",
    "CC = FF.linear(AA, BB)\n",
    "DD = CC.sum()\n",
    "DD.backward()\n",
    "\n",
    "\n",
    "arrays_are_close(D.grad.detach().numpy(), DD.grad) # compare de/da\n",
    "\n",
    "\n"
   ],
   "id": "1bdb2f6afa8431b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Example 4: Matrix Inversion Using a Linear Model",
   "id": "6e313b7469d79100"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T08:49:59.162479Z",
     "start_time": "2024-11-21T08:49:58.800021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Matrix Inverse Example\n",
    "A = Tensor([\n",
    "    [4.0, 7.0],\n",
    "    [2.0, 6.0]\n",
    "])\n",
    "\n",
    "\n",
    "inverse_model = Linear(2, 2, bias=False)\n",
    "\n",
    "def inverse_loss(A, A_inv):\n",
    "    identity = Tensor(np.eye(A.shape[0]))\n",
    "    return ((FF.linear(A, A_inv) - identity) ** 2).sum()\n",
    "\n",
    "optim = Adam(inverse_model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    optim.zero_grad()\n",
    "    A_inv = inverse_model(A)\n",
    "    loss = inverse_loss(A, A_inv)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.data}\")\n",
    "\n",
    "# Result\n",
    "print(\"Original Matrix:\\n\", A.data)\n",
    "print(\"Calculated Inverse:\\n\", inverse_model.weight.data)\n",
    "print(\"Product Result:\\n\", FF.linear(A, A_inv))\n",
    "\n"
   ],
   "id": "b10338a82bbe0770",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Linear' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 8\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Matrix Inverse Example\u001B[39;00m\n\u001B[1;32m      2\u001B[0m A \u001B[38;5;241m=\u001B[39m Tensor([\n\u001B[1;32m      3\u001B[0m     [\u001B[38;5;241m4.0\u001B[39m, \u001B[38;5;241m7.0\u001B[39m],\n\u001B[1;32m      4\u001B[0m     [\u001B[38;5;241m2.0\u001B[39m, \u001B[38;5;241m6.0\u001B[39m]\n\u001B[1;32m      5\u001B[0m ])\n\u001B[0;32m----> 8\u001B[0m inverse_model \u001B[38;5;241m=\u001B[39m \u001B[43mLinear\u001B[49m(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m2\u001B[39m, bias\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minverse_loss\u001B[39m(A, A_inv):\n\u001B[1;32m     11\u001B[0m     identity \u001B[38;5;241m=\u001B[39m Tensor(np\u001B[38;5;241m.\u001B[39meye(A\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'Linear' is not defined"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T09:02:39.722653Z",
     "start_time": "2024-11-21T09:02:39.713749Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f97905ea94225899",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T09:17:41.014317Z",
     "start_time": "2024-11-21T09:17:40.939187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn_torch\n",
    "import torch.nn.functional as F_torch\n",
    "\n",
    "from tensor import Tensor\n",
    "import nn as nn_mini\n",
    "import nn.functional as F_mini\n",
    "\n",
    "\n",
    "def arrays_are_close(arr_1, arr_2):\n",
    "    return np.allclose(arr_1, arr_2, atol=1e-9)\n",
    "\n",
    "\n",
    "mse_loss_torch = nn_torch.MSELoss(reduction='sum')\n",
    "mse_loss_mini = nn_mini.MSELoss(reduction='sum')\n",
    "\n",
    "\n",
    "a_torch = torch.tensor([[1, 2], [3, 4]], requires_grad=True, dtype=torch.float32)\n",
    "b_torch = torch.tensor([[5, 6], [7, 8]], requires_grad=True, dtype=torch.float32)\n",
    "y_torch = torch.tensor([[9, 2], [3, -1]], requires_grad=True, dtype=torch.float32)\n",
    "\n",
    "y_hat_torch = F_torch.linear(a_torch, b_torch)\n",
    "loss_torch = mse_loss_torch(y_hat_torch, y_torch)\n",
    "loss_torch.backward()\n",
    "\n",
    "a_mini = Tensor([[1, 2], [3, 4]])\n",
    "b_mini = Tensor([[5, 6], [7, 8]])\n",
    "y_mini = Tensor([[9, 2], [3, -1]])\n",
    "\n",
    "y_hat_mini = F_mini.linear(a_mini, b_mini)\n",
    "loss_mini = mse_loss_mini(y_hat_mini, y_mini)\n",
    "loss_mini.backward()\n",
    "\n",
    "\n",
    "print(arrays_are_close(a_torch.grad.detach().numpy(), a_mini.grad))\n",
    "print(arrays_are_close(b_torch.grad.detach().numpy(), b_mini.grad))"
   ],
   "id": "ca92c38c99c4c357",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T09:17:42.334453Z",
     "start_time": "2024-11-21T09:17:42.318564Z"
    }
   },
   "cell_type": "code",
   "source": "a_torch.grad, a_mini.grad",
   "id": "a7e059069ad03143",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 374.,  432.],\n",
       "         [1116., 1296.]]),\n",
       " array([[ 374.,  432.],\n",
       "        [1116., 1296.]], dtype=float32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T09:34:44.662737Z",
     "start_time": "2024-11-21T09:34:44.593707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nn import Linear, Module, MSELoss\n",
    "from optim import Adam\n",
    "from tensor import Tensor\n",
    "import nn.functional as F\n",
    "\n",
    "\n",
    "class MLP(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_1 = Linear(3, 3)\n",
    "        self.linear_2 = Linear(3, 6)\n",
    "        self.linear_3 = Linear(6, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.linear_1(x))\n",
    "        x = F.tanh(self.linear_2(x))\n",
    "        x = F.tanh(self.linear_3(x))\n",
    "        return x\n",
    "\n",
    "model = MLP()\n",
    "optim = Adam(model.parameters())\n",
    "criterion = MSELoss()\n",
    "\n",
    "\n",
    "X = Tensor([[2.0, 3.0, -1.0], [3.0, -1.0, 0.5], [0.5, 1.0, 1.0], [1.0, 1.0, -1.0]])\n",
    "Y = Tensor([[1.0], [-1.0], [-1.0], [1.0]])\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    y_hat = model(X)\n",
    "    loss = criterion(y_hat, Y)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    print(f\"Epoch {epoch}, Loss: {loss.data}\")"
   ],
   "id": "9e8014b72e66c7ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.9441636800765991\n",
      "Epoch 1, Loss: 1.9351037740707397\n",
      "Epoch 2, Loss: 1.924615502357483\n",
      "Epoch 3, Loss: 1.912492036819458\n",
      "Epoch 4, Loss: 1.8985000848770142\n",
      "Epoch 5, Loss: 1.882373332977295\n",
      "Epoch 6, Loss: 1.863801121711731\n",
      "Epoch 7, Loss: 1.842448353767395\n",
      "Epoch 8, Loss: 1.8179742097854614\n",
      "Epoch 9, Loss: 1.7900376319885254\n",
      "Epoch 10, Loss: 1.758312463760376\n",
      "Epoch 11, Loss: 1.7225126028060913\n",
      "Epoch 12, Loss: 1.6824241876602173\n",
      "Epoch 13, Loss: 1.637947916984558\n",
      "Epoch 14, Loss: 1.5891469717025757\n",
      "Epoch 15, Loss: 1.5362987518310547\n",
      "Epoch 16, Loss: 1.4799386262893677\n",
      "Epoch 17, Loss: 1.4208837747573853\n",
      "Epoch 18, Loss: 1.3602203130722046\n",
      "Epoch 19, Loss: 1.2992528676986694\n",
      "Epoch 20, Loss: 1.2394320964813232\n",
      "Epoch 21, Loss: 1.1823170185089111\n",
      "Epoch 22, Loss: 1.1295578479766846\n",
      "Epoch 23, Loss: 1.0827854871749878\n",
      "Epoch 24, Loss: 1.0433828830718994\n",
      "Epoch 25, Loss: 1.0122207403182983\n",
      "Epoch 26, Loss: 0.9894610643386841\n",
      "Epoch 27, Loss: 0.9744916558265686\n",
      "Epoch 28, Loss: 0.9659960269927979\n",
      "Epoch 29, Loss: 0.9621586799621582\n",
      "Epoch 30, Loss: 0.9609485864639282\n",
      "Epoch 31, Loss: 0.9603905081748962\n",
      "Epoch 32, Loss: 0.9587616920471191\n",
      "Epoch 33, Loss: 0.954695463180542\n",
      "Epoch 34, Loss: 0.94720059633255\n",
      "Epoch 35, Loss: 0.9356277585029602\n",
      "Epoch 36, Loss: 0.9196127653121948\n",
      "Epoch 37, Loss: 0.8990200757980347\n",
      "Epoch 38, Loss: 0.8738956451416016\n",
      "Epoch 39, Loss: 0.8444306254386902\n",
      "Epoch 40, Loss: 0.8109346032142639\n",
      "Epoch 41, Loss: 0.7738119959831238\n",
      "Epoch 42, Loss: 0.7335402965545654\n",
      "Epoch 43, Loss: 0.690646231174469\n",
      "Epoch 44, Loss: 0.6456826329231262\n",
      "Epoch 45, Loss: 0.5992100834846497\n",
      "Epoch 46, Loss: 0.5517891049385071\n",
      "Epoch 47, Loss: 0.5039900541305542\n",
      "Epoch 48, Loss: 0.4564222991466522\n",
      "Epoch 49, Loss: 0.4097742736339569\n",
      "Epoch 50, Loss: 0.3648362159729004\n",
      "Epoch 51, Loss: 0.32245901226997375\n",
      "Epoch 52, Loss: 0.2834187150001526\n",
      "Epoch 53, Loss: 0.2482314556837082\n",
      "Epoch 54, Loss: 0.21703889966011047\n",
      "Epoch 55, Loss: 0.18964798748493195\n",
      "Epoch 56, Loss: 0.1656794250011444\n",
      "Epoch 57, Loss: 0.14471453428268433\n",
      "Epoch 58, Loss: 0.12637674808502197\n",
      "Epoch 59, Loss: 0.11035194993019104\n",
      "Epoch 60, Loss: 0.09637830406427383\n",
      "Epoch 61, Loss: 0.08422914147377014\n",
      "Epoch 62, Loss: 0.07370003312826157\n",
      "Epoch 63, Loss: 0.06460202485322952\n",
      "Epoch 64, Loss: 0.05675949156284332\n",
      "Epoch 65, Loss: 0.05001041293144226\n",
      "Epoch 66, Loss: 0.04420733451843262\n",
      "Epoch 67, Loss: 0.03921809047460556\n",
      "Epoch 68, Loss: 0.0349259227514267\n",
      "Epoch 69, Loss: 0.03122895024716854\n",
      "Epoch 70, Loss: 0.028039181604981422\n",
      "Epoch 71, Loss: 0.02528121881186962\n",
      "Epoch 72, Loss: 0.022890836000442505\n",
      "Epoch 73, Loss: 0.02081354521214962\n",
      "Epoch 74, Loss: 0.01900325156748295\n",
      "Epoch 75, Loss: 0.017421003431081772\n",
      "Epoch 76, Loss: 0.01603391394019127\n",
      "Epoch 77, Loss: 0.01481420174241066\n",
      "Epoch 78, Loss: 0.013738374225795269\n",
      "Epoch 79, Loss: 0.012786546722054482\n",
      "Epoch 80, Loss: 0.011941852979362011\n",
      "Epoch 81, Loss: 0.011189962737262249\n",
      "Epoch 82, Loss: 0.010518672876060009\n",
      "Epoch 83, Loss: 0.009917567484080791\n",
      "Epoch 84, Loss: 0.009377737529575825\n",
      "Epoch 85, Loss: 0.008891541510820389\n",
      "Epoch 86, Loss: 0.008452409878373146\n",
      "Epoch 87, Loss: 0.008054682984948158\n",
      "Epoch 88, Loss: 0.0076934704557061195\n",
      "Epoch 89, Loss: 0.007364536169916391\n",
      "Epoch 90, Loss: 0.007064203731715679\n",
      "Epoch 91, Loss: 0.006789274048060179\n",
      "Epoch 92, Loss: 0.006536956410855055\n",
      "Epoch 93, Loss: 0.006304810754954815\n",
      "Epoch 94, Loss: 0.006090699229389429\n",
      "Epoch 95, Loss: 0.00589274475350976\n",
      "Epoch 96, Loss: 0.005709294695407152\n",
      "Epoch 97, Loss: 0.005538892466574907\n",
      "Epoch 98, Loss: 0.005380250047892332\n",
      "Epoch 99, Loss: 0.005232227500528097\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d963078d24946cd9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4d3ae6dd816c1623"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
